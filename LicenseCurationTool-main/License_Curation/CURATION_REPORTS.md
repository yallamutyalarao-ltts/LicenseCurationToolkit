# AI Curation Reports - Implementation Summary

## Overview

The enhanced workflow now generates **FIVE types of AI-powered and comparison reports**:

### 1. Main ORT Curation Report (`curation-report-main.html`)
**Generated by:** `ort_curation_script_html.py` (your original script)

**Purpose:** Comprehensive compliance analysis of all ORT results

**Features:**
- Executive summary with overall project status
- Complete license inventory and distribution
- Package-by-package analysis
- Risk assessment (high/medium/low priority issues)
- Actionable recommendations
- Go/No-Go compliance verdict
- Beautiful gradient styling with LTTS branding

**When it runs:**
- Always runs if ORT analyzer completes successfully
- Requires `AZURE_OPENAI_API_KEY` secret
- Uses Azure OpenAI model: `gpt-4.1-mini`

### 2. License Conflict Analysis Report (`curation-report-conflicts.html`)
**Generated by:** `enhanced_ai_curation.py` (new multi-tool script)

**Purpose:** Deep analysis of license conflicts and uncertain packages

**Features:**
- Multi-tool comparison (ORT + ScanCode + SPDX)
- Conflict resolution recommendations
- Risk-level assessment for each conflict
- Specific actionable steps for each package
- Links to source repositories and documentation

**When it runs:**
- Only runs if uncertain packages are detected
- Uses enhanced SPDX if ScanCode scanning completed
- Requires both `AZURE_OPENAI_API_KEY` and `AZURE_OPENAI_ENDPOINT` secrets
- Uses Azure OpenAI model: `gpt-4`

### 3. Missing Licenses Analysis Report (`curation-report-missing-licenses.html`)
**Generated by:** `ai_missing_licenses_analyzer.py`

**Purpose:** AI research and suggestions for packages with blank/missing licenses

**Features:**
- AI-suggested licenses for NOASSERTION/blank packages
- Confidence levels (High/Medium/Low)
- Reasoning for each suggestion
- Step-by-step verification guides
- Alternative licenses to check
- Risk assessments (Low/Medium/High)
- Quick links to package registry, homepage, repository
- Ready-to-use curation commands (copy/paste)

**When it runs:**
- Only runs if packages with NOASSERTION/blank licenses exist
- Requires `AZURE_OPENAI_API_KEY` secret
- Uses Azure OpenAI model: `gpt-4o-mini`
- Analyzes up to 15 packages per run (cost control)

**‚ö†Ô∏è IMPORTANT:** AI suggestions are advisory only - always verify manually!

### 4. Multi-Layer License Comparison (`license-comparison.html`) ‚≠ê NEW
**Generated by:** `generate_license_comparison.py`

**Purpose:** Consolidated view comparing licenses from all three sources

**Features:**
- Side-by-side comparison of ORT, PyPI, and ScanCode results
- Package-by-package comparison table
- Conflict detection (sources disagree)
- Missing license identification (no sources found)
- Color-coded status indicators:
  - üü¢ Green: All sources agree (consistent)
  - üü° Yellow: Sources conflict (need resolution)
  - üî¥ Red: No license found in any source
- Sortable and filterable table
- Quick links to package details
- Statistics summary

**When it runs:**
- Always runs if ORT analysis completes
- No AI required (comparison logic only)
- Uses PyPI results if available
- Uses ScanCode results if available
- Gracefully handles missing data sources

### 5. AI Multi-Layer Resolution (`ai-multilayer-resolution.html`) ‚≠ê NEW
**Generated by:** `ai_multilayer_resolution.py`

**Purpose:** AI-powered intelligent resolution for conflicts and missing licenses

**Features:**

**Section 1: ‚úÖ Resolved Packages**
- Packages with consistent licenses across all sources
- Shows which sources confirmed the license
- Grid layout with green cards
- Typically 80-95% of packages

**Section 2: ‚ö†Ô∏è License Conflicts**
- Packages where sources disagree
- AI analysis for each conflict:
  - Recommended license (which one is correct)
  - Reasoning (why this license is most likely)
  - Conflict explanation (why sources disagree)
  - Action required (specific steps)
  - Confidence level (High/Medium/Low)
  - Verification steps
  - Links to homepage and repository

**Section 3: ‚ùå Missing Licenses**
- Packages with no license found in any source
- AI suggestions based on:
  - Repository URL patterns
  - Package ecosystem standards
  - Package name patterns
  - Organization/author patterns
- For each package:
  - Suggested license
  - Reasoning
  - Confidence level
  - Direct GitHub LICENSE URL (if available)
  - Action steps
  - Verification steps
  - Alternative licenses
  - Risk level

**When it runs:**
- Runs if ORT analysis completes
- Requires `AZURE_OPENAI_API_KEY` and `AZURE_OPENAI_ENDPOINT`
- Uses Azure OpenAI model: `gpt-4.1-mini` (configurable via `AZURE_OPENAI_MODEL`)
- API Version: `2025-01-01-preview`
- Analyzes up to 15 conflicts + 10 missing packages per run

**‚ö†Ô∏è IMPORTANT:** AI suggestions are advisory only - always verify manually!

## Workflow Stages

### Stage 5a: Main ORT Curation
```bash
python3 ort_curation_script_html.py
```
- Analyzes `ort-results/analyzer/analyzer-result.yml`
- Generates timestamped report: `curation-report-YYYYMMDD-HHMMSS.html`
- Copies to `curation-report-main.html` for deployment

### Stage 5b: Enhanced Conflict Analysis
```bash
python3 enhanced_ai_curation.py \
  --ort-results ort-results/analyzer/analyzer-result.yml \
  --spdx-doc enhanced-spdx/bom-enhanced-fixed.spdx.json \
  --uncertain-packages uncertain-packages/uncertain-packages.json \
  --output curation-report-conflicts.html
```
- Only runs if uncertain packages exist
- Uses ScanCode-enhanced SPDX if available
- Generates focused conflict analysis

### Stage 5c: Missing Licenses AI Analysis
```bash
python3 ai_missing_licenses_analyzer.py \
  uncertain-packages/uncertain-packages.json \
  curation-report-missing-licenses.html
```
- Only runs if packages with missing licenses exist
- Analyzes up to 15 packages
- Generates AI suggestions (advisory only)

### Stage 5d: Multi-Layer License Comparison ‚≠ê NEW
```bash
python3 generate_license_comparison.py \
  --ort-result ort-results/analyzer/analyzer-result.yml \
  --pypi-results pypi-licenses/pypi-licenses-full.json \
  --scancode-dir scancode-results \
  --uncertain-packages uncertain-packages/uncertain-packages.json \
  --spdx ort-results/reporter/bom.spdx.yml \
  --output license-comparison.html
```
- Always runs if ORT completes
- Compares all three sources
- No AI required

### Stage 5e: AI Multi-Layer Resolution ‚≠ê NEW
```bash
python3 ai_multilayer_resolution.py \
  --ort-result ort-results/analyzer/analyzer-result.yml \
  --pypi-results pypi-licenses/pypi-licenses-full.json \
  --scancode-dir scancode-results \
  --uncertain-packages uncertain-packages/uncertain-packages.json \
  --output ai-multilayer-resolution.html
```
- Runs if ORT completes
- Shows resolved packages first
- AI analyzes conflicts and missing licenses
- Limit: 15 conflicts + 10 missing

## GitHub Pages Deployment

All reports are copied to the `public/` directory and deployed to GitHub Pages:

```
https://<username>.github.io/<repo>/
‚îú‚îÄ‚îÄ index.html (landing page with links to all reports)
‚îú‚îÄ‚îÄ curation-report-main.html (primary AI report)
‚îú‚îÄ‚îÄ curation-report-conflicts.html (conflict analysis, if conflicts exist)
‚îú‚îÄ‚îÄ curation-report-missing-licenses.html (AI missing licenses, if applicable)
‚îú‚îÄ‚îÄ license-comparison.html (multi-layer comparison) ‚≠ê NEW
‚îú‚îÄ‚îÄ ai-multilayer-resolution.html (AI resolution report) ‚≠ê NEW
‚îú‚îÄ‚îÄ pypi-licenses-report.html (PyPI fetch results) ‚≠ê NEW
‚îú‚îÄ‚îÄ scancode-summary.html (consolidated ScanCode report)
‚îú‚îÄ‚îÄ scan-report-web-app.html (ORT WebApp)
‚îú‚îÄ‚îÄ scan-report.html (ORT static HTML)
‚îú‚îÄ‚îÄ bom.cyclonedx.json (CycloneDX SBOM)
‚îú‚îÄ‚îÄ bom.spdx.yml (Original SPDX)
‚îú‚îÄ‚îÄ bom-enhanced.spdx.json (Enhanced SPDX, if ScanCode ran)
‚îú‚îÄ‚îÄ scancode-reports/ (individual package reports)
‚îÇ   ‚îú‚îÄ‚îÄ package-1.0.0.html (native ScanCode HTML)
‚îÇ   ‚îú‚îÄ‚îÄ package-1.0.0.json (raw scan data)
‚îÇ   ‚îî‚îÄ‚îÄ package-1.0.0.yml (raw scan data)
‚îî‚îÄ‚îÄ uncertain-packages-report.md (markdown report)
```

## Required GitHub Secrets

### For Main Report Only (Minimum):
```
AZURE_OPENAI_API_KEY
```

### For All AI Reports (Recommended):
```
AZURE_OPENAI_API_KEY
AZURE_OPENAI_ENDPOINT (optional, has default)
AZURE_OPENAI_MODEL (optional, defaults to gpt-4.1-mini)
```

**‚ö†Ô∏è Important:** `AZURE_OPENAI_MODEL` should be your **deployment name** from Azure Portal, NOT the model name.
- ‚úÖ Correct: `gpt-4.1-mini` (your deployment name)
- ‚ùå Wrong: `gpt-4o-mini` (model name)

See `AZURE_OPENAI_SETUP.md` for detailed setup instructions.

## What You'll See in Workflow Logs

### Check AI Curation Prerequisites:
```
üîç Checking prerequisites for AI curation...

Checking required files:
  ‚úì ORT analyzer results found
  ‚úì Uncertain packages found
  ‚úì SPDX document found

Checking Azure OpenAI configuration:
  ‚úì API key configured
  ‚úì Endpoint configured
```

### Generate Main ORT Curation Report:
```
ü§ñ Stage 5a: Generating main ORT curation report...
Running ort_curation_script_html.py...
‚úÖ Main curation report generated: curation-report-20250102-140530.html
   Size: 125847 bytes
‚úÖ Copied to curation-report-main.html for deployment
```

### Generate Enhanced Conflict Analysis:
```
ü§ñ Stage 5b: Generating enhanced conflict analysis...
Found 12 uncertain packages requiring analysis
Using enhanced SPDX: enhanced-spdx/bom-enhanced-fixed.spdx.json
Running enhanced_ai_curation.py...
‚úÖ Conflict analysis report generated (45123 bytes)
```

## Troubleshooting

### No curation report generated

**Check 1: Azure OpenAI Credentials**
```
‚ö†Ô∏è  AZURE_OPENAI_API_KEY not set, skipping AI report...
```
**Solution:** Add `AZURE_OPENAI_API_KEY` secret in GitHub repository settings

**Check 2: ORT Analyzer Failed**
```
‚ùå ORT analyzer results not found!
```
**Solution:** Check earlier workflow steps - ORT analyzer must complete successfully

**Check 3: API Errors**
Look in `ort-curation.log` or `conflict-analysis.log` for errors like:
- `Authentication failed` - Invalid API key
- `Resource not found` - Wrong endpoint or deployment name
- `Rate limit exceeded` - Too many requests

### Only one report generated

This is normal! The conflict analysis report only generates when:
1. Uncertain packages are detected AND
2. Azure OpenAI is fully configured (both key and endpoint)

If all your packages have clear licenses, only the main report will be generated (which is good!).

### Reports are small (< 10KB)

The reports might be fallback/error pages. Check the workflow logs for:
```
‚ö†Ô∏è  No curation report generated, check ort-curation.log
```

Then examine the log files for the specific error.

## Next Steps

1. **Push the updated workflow:**
   ```bash
   git add enhanced-ort-workflow.yml generate_landing_page.py
   git commit -m "Integrate original ORT curation script + enhanced conflict analysis"
   git push
   ```

2. **Verify Azure OpenAI secrets are set:**
   - Go to GitHub repository ‚Üí Settings ‚Üí Secrets and variables ‚Üí Actions
   - Confirm `AZURE_OPENAI_API_KEY` exists
   - Optionally add `AZURE_OPENAI_ENDPOINT` (or script will use default)

3. **Watch the workflow run:**
   - Check "Check AI curation prerequisites" step
   - Watch for successful report generation
   - Download artifacts if needed

4. **View reports on GitHub Pages:**
   - Wait for deployment to complete
   - Visit `https://<username>.github.io/<repo>/`
   - Click on "AI Curation Report" (main) and "License Conflict Analysis" (if applicable)

## Model Configuration

### Main Report (ort_curation_script_html.py):
- **Model**: `gpt-4.1-mini`
- **Temperature**: 0.3 (deterministic)
- **Max Tokens**: 4000
- **Deployment**: Configured in script line 576

### Conflict Analysis (enhanced_ai_curation.py):
- **Model**: `gpt-4`
- **Temperature**: 0.3 (deterministic)
- **Max Tokens**: 1000 per conflict
- **Limit**: First 20 conflicts to avoid token limits

## Cost Optimization

**Main Report:**
- Runs once per workflow
- Analyzes all packages
- ~3000-4000 tokens output

**Conflict Analysis:**
- Only runs if needed
- Limited to 20 conflicts max
- ~1000 tokens per conflict

**Total estimated cost per run:**
- With conflicts: ~$0.15 - $0.30 USD
- Without conflicts: ~$0.05 - $0.10 USD
- (Based on GPT-4 pricing as of 2025)

## Success Criteria

‚úÖ **Fully Working System:**
```
‚úì ORT analyzer completes
‚úì Main curation report generated (>100KB)
‚úì Uncertain packages detected (if applicable)
‚úì Conflict analysis generated (if needed)
‚úì Both reports deployed to GitHub Pages
‚úì Landing page shows both reports
```

## Support

If issues persist:
1. Check workflow logs for "Check AI curation prerequisites"
2. Review `ort-curation.log` and `conflict-analysis.log` outputs
3. Verify Azure OpenAI deployment name matches your configuration
4. Test scripts locally with sample data
